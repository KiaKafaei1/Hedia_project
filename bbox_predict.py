# -*- coding: utf-8 -*-
"""bbox_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z2jPNx_Q3qr2NbUSAgbnWN0y93hfHc4y
"""

import matplotlib
import numpy as np
import pandas as pd
import torch 
import torchvision
import torch.nn as nn
import torch.nn.functional as F 
from torchvision import transforms
import cv2 
from PIL import Image
import matplotlib.pyplot as plt
import glob
import os
from IPython.display import clear_output
from skimage.io import imread
from skimage.transform import resize
from google.colab import drive

# run GPU .... 
if (torch.cuda.is_available()):
    device = torch.device("cuda")
    print(device, torch.cuda.get_device_name(0))
else:
    device= torch.device("cpu")
    print(device)

def bbox_predict(roi, roi_cls_loc, roi_cls_score, nms_thresh=0.7, n_test_pre_nms=100, n_test_post_nms=30, min_size=16, remove_background=True):

  roi_cls_loc1 = roi_cls_loc.detach().cpu().numpy()
  

  # remove background bboxes
  if remove_background:
    roi_cls_score = roi_cls_score[:,1:]
    roi_cls_loc1 = roi_cls_loc1[:,4:]


  m = nn.Softmax(dim=1)
  roi_cls_score = m(roi_cls_score)
  roi_cls_score = roi_cls_score.detach().cpu().numpy()

  labels = np.argmax(roi_cls_score, axis=1)
  labels = labels.astype(int)
  roi_cls_score = np.max(roi_cls_score, axis=1)


  index1 = (labels*4).astype(int)
  index = np.ones((len(roi_cls_loc1[:,0]),4))
  index[:,0] = index1
  index[:,1] = index1+1
  index[:,2] = index1+2
  index[:,3] = index1+3
  index = index.astype(int)


  roi_cls_loc = np.zeros((len(roi_cls_loc1[:,0]),4))


  for i in range(len(index[:,0])):
    for n in range(len(index[0,:])):
      roi_cls_loc[i,n] = roi_cls_loc1[i,index[i,n]]

  if roi_cls_loc.size==0 or roi_cls_score.size==0:
    print("Empty input: loc or score")

  # Normalize bbox
  # roi_cls_loc = (roi_cls_loc - np.mean(roi_cls_loc, axis=0)) / np.std(roi_cls_loc, axis=0)

  anchors = roi

  if anchors.size==0:
    print("Empty input: roi")

  anc_height = anchors[:, 2] - anchors[:, 0]
  anc_width = anchors[:, 3] - anchors[:, 1]
  anc_ctr_y = anchors[:, 0] + 0.5 * anc_height
  anc_ctr_x = anchors[:, 1] + 0.5 * anc_width
  # The 22500 anchor boxes location and labels predicted by RPN (convert to numpy)
  # format = (dy, dx, dh, dw)
  pred_anchor_locs_numpy = roi_cls_loc
  objectness_score_numpy = roi_cls_score

  dy = pred_anchor_locs_numpy[:, 0::4] # anchor box dy
  dx = pred_anchor_locs_numpy[:, 1::4] # dx
  dh = pred_anchor_locs_numpy[:, 2::4] # dh
  dw = pred_anchor_locs_numpy[:, 3::4] # dw


  # ctr_y = dy predicted by RPN * anchor_h + anchor_cy
  # ctr_x similar
  # h = exp(dh predicted by RPN) * anchor_h
  # w similar
  ctr_y = dy * anc_height[:, np.newaxis] + anc_ctr_y[:, np.newaxis]
  ctr_x = dx * anc_width[:, np.newaxis] + anc_ctr_x[:, np.newaxis]
  h = np.exp(dh) * anc_height[:, np.newaxis]
  w = np.exp(dw) * anc_width[:, np.newaxis]

  # get x0, y0, x1, y1:
  roi_loc_pred = np.zeros(pred_anchor_locs_numpy.shape)
  roi_loc_pred[:, 0::4] = ctr_y - 0.5 * h
  roi_loc_pred[:, 1::4] = ctr_x - 0.5 * w
  roi_loc_pred[:, 2::4] = ctr_y + 0.5 * h
  roi_loc_pred[:, 3::4] = ctr_x + 0.5 * w

  # clip the predicted boxes to the image
  img_size = (800, 800) #Image size
  roi_loc_pred[:, slice(0, 4, 2)] = np.clip(roi[:, slice(0, 4, 2)], 0, img_size[0])
  roi_loc_pred[:, slice(1, 4, 2)] = np.clip(roi[:, slice(1, 4, 2)], 0, img_size[1])


  # Remove predicted boxes with either height or width < threshold.
  hs = roi_loc_pred[:, 2] - roi_loc_pred[:, 0]
  ws = roi_loc_pred[:, 3] - roi_loc_pred[:, 1]
  keep = np.where((hs >= min_size) & (ws >= min_size))[0] #min_size=16
  roi_loc_pred = roi_loc_pred[keep, :]
  score = objectness_score_numpy[keep]
  labels = labels[keep]


  # Sort all (proposal, score) pairs by score from highest to lowest
  order = score.ravel().argsort()[::-1]


  #Take top pre_nms_topN (e.g. 12000 while training and 300 while testing)
  order = order[:n_test_pre_nms]
  score = score[order]
  labels = labels[order]
  roi_loc_pred = roi_loc_pred[order, :]

  # Take all the roi boxes [roi_array]
  y1 = roi_loc_pred[:, 0]
  x1 = roi_loc_pred[:, 1]
  y2 = roi_loc_pred[:, 2]
  x2 = roi_loc_pred[:, 3]

  # Find the areas of all the boxes [roi_area]
  areas = (x2 - x1 + 1) * (y2 - y1 + 1)
  #Take the indexes of order the probability score in descending order
  order = score.argsort()[::-1]
  keep = []
  while (order.size > 0):
      i = order[0] #take the 1st elt in order and append to keep
      keep.append(i)
      xx1 = np.maximum(x1[i], x1[order[1:]])
      yy1 = np.maximum(y1[i], y1[order[1:]])
      xx2 = np.minimum(x2[i], x2[order[1:]])
      yy2 = np.minimum(y2[i], y2[order[1:]])
      w = np.maximum(0.0, xx2 - xx1 + 1)
      h = np.maximum(0.0, yy2 - yy1 + 1)
      inter = w * h
      ovr = inter / (areas[i] + areas[order[1:]] - inter)
      inds = np.where(ovr <= nms_thresh)[0]
      order = order[inds + 1]
  keep = keep[:n_test_post_nms] # while training/testing , use accordingly
  roi_loc_pred = roi_loc_pred[keep] # the final region proposals
  score = score[keep]
  labels = labels[keep]

  return roi_loc_pred, score, labels

