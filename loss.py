# -*- coding: utf-8 -*-
"""loss.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13lQiLDH3_PD0nJgzZCNKsj3bbXYRJ65u
"""

import matplotlib
import numpy as np
import pandas as pd
import torch 
import torchvision
import torch.nn as nn
import torch.nn.functional as F 
from torchvision import transforms
import cv2 
from PIL import Image
import matplotlib.pyplot as plt
import glob
import os
from IPython.display import clear_output
from skimage.io import imread
from skimage.transform import resize
from google.colab import drive

# Self defined models and functions
from prepare_img import prepare_img
from anchorbox_generator import Anchorbox_generator
from class_rpn_vgg16 import ClassRPN, vgg16
from detection import Detection_Network
from nms_detection_loss import nms, sampleRoi
from bbox_predict import bbox_predict

# run GPU .... 
if (torch.cuda.is_available()):
    device = torch.device("cuda")
    print(device, torch.cuda.get_device_name(0))
else:
    device= torch.device("cpu")
    print(device)

def loss(out, criterion, rpn_lambda=10, roi_lambda=10):
  roi_cls_loc, roi_cls_score, rois = out['roi']
  pred_anchor_locs, objectness_score, pred_cls_scores = out['RPN']
  pos_index, neg_index, gt_roi_locs, gt_roi_labels, sample_roi, pos_roi_per_this_image = out['sampleROI']
  anchor_labels, anchor_locations, anchors = out['anchor']
  
  # LOSS RPN    
  # Rearrange so input and outputs align
  rpn_loc = pred_anchor_locs[0]
  rpn_score = pred_cls_scores[0]
  gt_rpn_loc = torch.from_numpy(anchor_locations)
  gt_rpn_score = torch.from_numpy(anchor_labels)

  # Normalize
  # rpn_loc = (rpn_loc - torch.mean(rpn_loc, 0))/torch.std(rpn_loc,0)

  # print("RPN")
  # print(torch.min(rpn_loc), torch.max(rpn_loc))
  # print(torch.min(gt_rpn_loc), torch.max(gt_rpn_loc))

  # Calculate cross entropy loss for classification
  # m = nn.Softmax(dim=1)
  # rpn_score = m(rpn_score)
  # labels_rpn = torch.argmax(rpn_score, dim=1)
  # rpn_score = torch.max(rpn_score, dim=1)
  #one_hot_gt_rpn_score = torch.nn.functional.one_hot(gt_rpn_score.to(torch.int64), num_classes = 2)  
  rpn_cls_loss = criterion(rpn_score, gt_rpn_score.long().to(device))

  # Find the L1 regression loss for the bounding boxes
  # Find bounding boxes with positive label
  pos = gt_rpn_score > 0
  mask = pos.unsqueeze(1).expand_as(rpn_loc)

  # Take the bounding boxes with positive label
  mask_loc_preds = rpn_loc[mask].view(-1, 4)
  mask_loc_targets = gt_rpn_loc[mask].view(-1, 4)

  # Apply regression loss to the found bounding boxes
  x = torch.abs(mask_loc_targets.to(device) - mask_loc_preds.to(device))
  rpn_loc_loss = ((x < 1).float() * 0.5 * x**2) + ((x >= 1).float() * (x-0.5))

  # Combine the classification and regression loss to get the total loss for RPN
  # Define hyperparameter lambda
  N_reg = (gt_rpn_score >0).float().sum()
  rpn_loc_loss = rpn_loc_loss.sum() / N_reg
  rpn_loc_loss[torch.isnan(rpn_loc_loss)]=0
  rpn_loss = rpn_cls_loss + (rpn_lambda * rpn_loc_loss)



  # LOSS detection
  gt_roi_labels=gt_roi_labels.flatten()
  # Converting ground truth to torch variable
  gt_roi_loc = torch.from_numpy(gt_roi_locs)
  gt_roi_label = torch.from_numpy(np.float32(gt_roi_labels)).long()

  # Classification loss
  # m = nn.Softmax(dim=1)
  # roi_cls_score = m(roi_cls_score)
  # labels_roi = torch.argmax(roi_cls_score, dim=1)
  # roi_cls_score = torch.max(roi_cls_score, dim=1)
  # one_hot_gt_roi_label = torch.nn.functional.one_hot(gt_roi_label, num_classes = 11)
  roi_cls_loss = criterion(roi_cls_score, gt_roi_label.to(device))
  
  # Regression loss
  n_sample = roi_cls_loc.shape[0]
  roi_loc = roi_cls_loc.view(n_sample, -1, 4)
  roi_loc = roi_loc[torch.arange(0, n_sample).long(), gt_roi_label]

  # Normalize
  # roi_loc = (roi_loc - torch.mean(roi_loc, 0))/torch.std(roi_loc, 0)
  
  # print("ROI")
  # print(torch.min(roi_loc1), torch.max(roi_loc1))
  # print(torch.min(roi_loc), torch.max(roi_loc))
  # print(torch.min(gt_roi_loc), torch.max(gt_roi_loc))

  # For Regression we use smooth L1 loss as defined in the Fast RCNN paper
  pos = gt_roi_label > 0
  mask = pos.unsqueeze(1).expand_as(roi_loc)
  
  # take those bounding boxes which have positve labels
  mask_loc_preds = roi_loc[mask].view(-1, 4)
  mask_loc_targets = gt_roi_loc[mask].view(-1, 4)
  x = torch.abs(mask_loc_targets.to(device) - mask_loc_preds.to(device))
  roi_loc_loss = ((x < 1).float() * 0.5 * x**2) + ((x >= 1).float() * (x-0.5))
  
  #roi_loc_loss.sum() is the total regression loss
  #roi_lambda is a hyperparameter
  N_reg = (gt_roi_labels >0).sum()
  roi_loc_loss = roi_loc_loss.sum() / N_reg
  roi_loc_loss[torch.isnan(roi_loc_loss)]=0
  roi_loss = roi_cls_loss + (roi_lambda * roi_loc_loss)

  total_loss = rpn_loss + roi_loss

  return total_loss, rpn_loss, roi_loss, roi_cls_loss, roi_loc_loss, rpn_cls_loss, rpn_loc_loss

